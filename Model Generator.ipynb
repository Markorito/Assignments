{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521190c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from micromlgen import port\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from os.path import basename\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc892f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(folder):\n",
    "    dataset = None\n",
    "    classmap = {}\n",
    "    for class_idx, filename in enumerate(glob('%s/*.csv' % folder)):\n",
    "        class_name = basename(filename)[:-4]\n",
    "        classmap[class_idx] = class_name\n",
    "        samples = np.loadtxt(filename, dtype=float, delimiter=',')\n",
    "        labels = np.ones((len(samples), 1)) * class_idx\n",
    "        samples = np.hstack((samples, labels))\n",
    "        dataset = samples if dataset is None else np.vstack((dataset, samples))\n",
    "\n",
    "    return dataset, classmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e2fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your samples in the dataset folder\n",
    "# one class per file\n",
    "# one feature vector per line, in CSV format\n",
    "features, classmap = load_features('dataset/')\n",
    "X, y = features[:, :-1], features[:, -1]\n",
    "classifier = RandomForestClassifier(n_estimators=30, max_depth=10).fit(X, y)\n",
    "c_code = port(classifier, classmap=classmap)\n",
    "print(c_code)\n",
    "\n",
    "f = open(\"model.h\", \"w\")\n",
    "f.write(c_code)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b18c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting our dataset to test our models later\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.3, random_state = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02256207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient Classifier with Sklearn\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Creating the SGD Classifier\n",
    "SGDClf = linear_model.SGDClassifier(max_iter = 1000, tol=1e-3,penalty = \"elasticnet\")\n",
    "\n",
    "#Training the model\n",
    "SGDClf.fit(X_train, y_train)\n",
    "\n",
    "#Getting predictions\n",
    "y_pred_sgd = SGDClf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223f3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppot Vector Classifier with Sklearn\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Create a svm Classifier\n",
    "SVMClf = SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Training the model\n",
    "SVMClf.fit(X_train, y_train)\n",
    "\n",
    "#Getting predictions\n",
    "y_pred_svm = SVMClf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd14bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the models\n",
    "from sklearn import metrics\n",
    "#Accuracy\n",
    "print(f'The accuracy for the SGD is: {metrics.accuracy_score(y_test, y_pred_sgd)}')\n",
    "print(f'The accuracy for the SVM is: {metrics.accuracy_score(y_test, y_pred_svm)}')\n",
    "\n",
    "#Precision\n",
    "sgdprecision = metrics.precision_score(y_test, y_pred_sgd, average = 'macro')\n",
    "svcprecision = metrics.precision_score(y_test, y_pred_svm, average = 'macro')\n",
    "\n",
    "print(f'The precision score for the SGD is: {sgdprecision}')\n",
    "print(f'The precision score for the SVM is: {svcprecision}')\n",
    "\n",
    "#Recall\n",
    "sgdrecall = metrics.recall_score(y_test, y_pred_sgd, average = 'weighted')\n",
    "svcrecall = metrics.recall_score(y_test, y_pred_svm, average = 'weighted')\n",
    "print(f'The recall score for the SGD is: {sgdrecall}')\n",
    "print(f'The recall score for the SVM is: {svcrecall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16976f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputting a confusion matrix for our models\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "sgd_cm = confusion_matrix(y_test, y_pred_sgd)\n",
    "\n",
    "svc_cm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "disp_sgd = ConfusionMatrixDisplay(confusion_matrix=sgd_cm, display_labels=SGDClf.classes_)\n",
    "disp_svc = ConfusionMatrixDisplay(confusion_matrix=svc_cm, display_labels=SVMClf.classes_)\n",
    "\n",
    "disp_sgd.plot()\n",
    "disp_svc.plot()\n",
    "\n",
    "plt.savefig('confusionmatrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb8b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(SGDClf, open(\"SGDClf.pkl\", \"wb\"))\n",
    "pickle.dump(SVMClf, open(\"SVMClf.pkl\", \"wb\"))\n",
    "pickle.dump(classifier, open(\"classifier.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19453591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
